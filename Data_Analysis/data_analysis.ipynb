{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_paths = 'D:/globit/Images/Infrared/globit_nas_07_flatfish_size_label/yolo/'\n",
    "for label_path in Path(label_paths).glob('*.txt'):\n",
    "    print(label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for label_path in Path(label_paths).glob('*.txt'):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            numbers = list(map(float, line.strip().split()))\n",
    "            all_data.append(numbers)\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"class\", \"x_center\", \"y_center\", \"width\", \"height\",\n",
    "    \"front_key_x\", \"front_key_y\", \"front_key_vis\",\n",
    "    \"tail_key_x\", \"tail_key_y\", \"tail_key_vis\",\n",
    "    \"right_key_x\", \"right_key_y\", \"right_key_vis\",\n",
    "    \"left_key_x\", \"left_key_y\", \"left_key_vis\"\n",
    "]\n",
    "df.columns = column_names\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 3, figsize=(18, 24))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "cols_to_plot = [\n",
    "    \"class\", \"x_center\", \"y_center\", \"width\", \"height\",\n",
    "    \"front_key_x\", \"front_key_y\", \"tail_key_x\", \"tail_key_y\",\n",
    "    \"right_key_x\", \"right_key_y\", \"left_key_x\", \"left_key_y\"\n",
    "]\n",
    "\n",
    "for idx, col in enumerate(cols_to_plot):\n",
    "    ax = axs[idx // 3, idx % 3]\n",
    "    df[col].hist(ax=ax, bins=30)\n",
    "    ax.set_title(f'{col} Histogram')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "for j in range(len(cols_to_plot), 15):\n",
    "    fig.delaxes(axs.flatten()[j])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(20, 24))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "keypoints = ['front', 'tail', 'right', 'left']\n",
    "colors = ['red', 'blue', 'green', 'purple']\n",
    "x_scale, y_scale = 3840, 2160\n",
    "\n",
    "for row, key in enumerate(keypoints):\n",
    "    for col, class_label in enumerate([0, 1]):\n",
    "        ax = axes[row, col]\n",
    "        subset = df[df[\"class\"] == class_label]\n",
    "        ax.scatter(subset[f'{key}_key_x'] * x_scale,\n",
    "                   subset[f'{key}_key_y'] * y_scale,\n",
    "                   color=colors[row], alpha=0.7)\n",
    "        ax.set_title(f'Class {class_label} - {key.capitalize()} Keypoints')\n",
    "        ax.set_xlabel('X Coordinate')\n",
    "        ax.set_ylabel('Y Coordinate')\n",
    "        ax.grid(True)\n",
    "        ax.set_xlim(0, x_scale)\n",
    "        ax.set_ylim(0, y_scale)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errors_idx = []\n",
    "threshold = 1e-3\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    vec_forward = np.array([\n",
    "        row[\"tail_key_x\"] - row[\"front_key_x\"],\n",
    "        row[\"tail_key_y\"] - row[\"front_key_y\"]\n",
    "    ])\n",
    "    vec_rl = np.array([\n",
    "        row[\"left_key_x\"] - row[\"right_key_x\"],\n",
    "        row[\"left_key_y\"] - row[\"right_key_y\"]\n",
    "    ])\n",
    "\n",
    "    norm_f = np.linalg.norm(vec_forward)\n",
    "    norm_rl = np.linalg.norm(vec_rl)\n",
    "\n",
    "    if norm_f == 0 or norm_rl == 0:\n",
    "        continue\n",
    "\n",
    "    vec_forward_normalized = vec_forward / norm_f\n",
    "    vec_rl_normalized = vec_rl / norm_rl\n",
    "\n",
    "    cross_z = np.cross(vec_forward_normalized, vec_rl_normalized)\n",
    "\n",
    "    if cross_z >= -threshold:\n",
    "        df_errors_idx.append(i)\n",
    "\n",
    "df_errors = df.loc[df_errors_idx].reset_index(drop=True)\n",
    "df_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = ['front', 'tail', 'right', 'left']\n",
    "colors = {'front': 'red', 'tail': 'blue', 'right': 'green', 'left': 'purple'}\n",
    "x_scale, y_scale = 3840, 2160\n",
    "\n",
    "num_cols = 4\n",
    "num_rows = 3\n",
    "num_samples = num_cols * num_rows\n",
    "\n",
    "if len(df_errors) <= num_samples:\n",
    "    selected_samples = df_errors\n",
    "else:\n",
    "    selected_samples = df_errors.sample(num_samples).reset_index(drop=True)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, row in enumerate(selected_samples.itertuples()):\n",
    "    ax = axes[idx]\n",
    "    for key in keypoints:\n",
    "        ax.scatter(\n",
    "            getattr(row, f\"{key}_key_x\") * x_scale,\n",
    "            getattr(row, f\"{key}_key_y\") * y_scale,\n",
    "            color=colors[key],\n",
    "            label=key if idx == 0 else \"\",\n",
    "            s=120\n",
    "        )\n",
    "\n",
    "    ax.plot(\n",
    "        [row.front_key_x * x_scale, row.tail_key_x * x_scale],\n",
    "        [row.front_key_y * y_scale, row.tail_key_y * y_scale],\n",
    "        'k--', alpha=0.6\n",
    "    )\n",
    "    ax.plot(\n",
    "        [row.right_key_x * x_scale, row.left_key_x * x_scale],\n",
    "        [row.right_key_y * y_scale, row.left_key_y * y_scale],\n",
    "        'k--', alpha=0.6\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Sample {row.Index}\")\n",
    "    ax.set_xlim(0, x_scale)\n",
    "    ax.set_ylim(0, y_scale)\n",
    "    ax.grid(True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "for idx in range(len(selected_samples), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frame = {}\n",
    "\n",
    "for label_path in Path(label_paths).glob('*.txt'):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        numbers = list(map(float, line.strip().split()))\n",
    "        data.append(numbers)\n",
    "\n",
    "    if not data:\n",
    "        print(f\"⚠️ 파일이 비어 있음: {label_path.name}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    if df.shape[1] != len(column_names):\n",
    "        print(f\"⚠️ 열 수 불일치: {label_path.name} (columns: {df.shape[1]})\")\n",
    "        continue\n",
    "\n",
    "    df.columns = column_names\n",
    "    all_frame[label_path.stem] = df\n",
    "\n",
    "all_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_rows = []\n",
    "\n",
    "for frame_name, df in all_frame.items():\n",
    "    for idx, row in df.iterrows():\n",
    "        vec_forward = np.array([\n",
    "            row[\"tail_key_x\"] - row[\"front_key_x\"],\n",
    "            row[\"tail_key_y\"] - row[\"front_key_y\"]\n",
    "        ])\n",
    "        vec_rl = np.array([\n",
    "            row[\"left_key_x\"] - row[\"right_key_x\"],\n",
    "            row[\"left_key_y\"] - row[\"right_key_y\"]\n",
    "        ])\n",
    "\n",
    "        norm_f = np.linalg.norm(vec_forward)\n",
    "        norm_rl = np.linalg.norm(vec_rl)\n",
    "\n",
    "        if norm_f == 0 or norm_rl == 0:\n",
    "            continue\n",
    "\n",
    "        vec_forward_normalized = vec_forward / norm_f\n",
    "        vec_rl_normalized = vec_rl / norm_rl\n",
    "\n",
    "        cross_z = np.cross(vec_forward_normalized, vec_rl_normalized)\n",
    "\n",
    "        if cross_z >= -threshold:\n",
    "            row_data = row.to_dict()\n",
    "            row_data[\"file_name\"] = frame_name\n",
    "            correction_rows.append(row_data)\n",
    "\n",
    "df_corrections = pd.DataFrame(correction_rows).reset_index(drop=True)\n",
    "df_corrections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 4\n",
    "num_rows = 3\n",
    "num_samples = num_cols * num_rows\n",
    "\n",
    "if len(df_corrections) <= num_samples:\n",
    "    selected_samples = df_corrections\n",
    "else:\n",
    "    selected_samples = df_corrections.sample(num_samples).reset_index(drop=True)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, row in enumerate(selected_samples.itertuples()):\n",
    "    ax = axes[idx]\n",
    "    for key in keypoints:\n",
    "        ax.scatter(\n",
    "            getattr(row, f\"{key}_key_x\") * x_scale,\n",
    "            getattr(row, f\"{key}_key_y\") * y_scale,\n",
    "            color=colors[key],\n",
    "            label=key if idx == 0 else \"\",\n",
    "            s=120\n",
    "        )\n",
    "\n",
    "    ax.plot(\n",
    "        [row.front_key_x * x_scale, row.tail_key_x * x_scale],\n",
    "        [row.front_key_y * y_scale, row.tail_key_y * y_scale],\n",
    "        'k--', alpha=0.6\n",
    "    )\n",
    "    ax.plot(\n",
    "        [row.right_key_x * x_scale, row.left_key_x * x_scale],\n",
    "        [row.right_key_y * y_scale, row.left_key_y * y_scale],\n",
    "        'k--', alpha=0.6\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{row.file_name}\")\n",
    "    ax.set_xlim(0, x_scale)\n",
    "    ax.set_ylim(0, y_scale)\n",
    "    ax.grid(True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# 범례 중복 제거\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "# 사용되지 않는 플롯 제거\n",
    "for idx in range(len(selected_samples), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_rows = []\n",
    "\n",
    "for frame_name, df in all_frame.items():\n",
    "    for idx, row in df.iterrows():\n",
    "        vec_forward = np.array([\n",
    "            row[\"tail_key_x\"] - row[\"front_key_x\"],\n",
    "            row[\"tail_key_y\"] - row[\"front_key_y\"]\n",
    "        ])\n",
    "        vec_rl = np.array([\n",
    "            row[\"left_key_x\"] - row[\"right_key_x\"],\n",
    "            row[\"left_key_y\"] - row[\"right_key_y\"]\n",
    "        ])\n",
    "\n",
    "        norm_f = np.linalg.norm(vec_forward)\n",
    "        norm_rl = np.linalg.norm(vec_rl)\n",
    "\n",
    "        if norm_f == 0 or norm_rl == 0:\n",
    "            continue\n",
    "\n",
    "        vec_forward_normalized = vec_forward / norm_f\n",
    "        vec_rl_normalized = vec_rl / norm_rl\n",
    "\n",
    "        cross_z = np.cross(vec_forward_normalized, vec_rl_normalized)\n",
    "\n",
    "        if cross_z >= -threshold:\n",
    "            row_data = row.to_dict()\n",
    "            row_data[\"file_name\"] = frame_name\n",
    "            row_data[\"original_index\"] = idx\n",
    "            correction_rows.append(row_data)\n",
    "\n",
    "original_df = pd.DataFrame(correction_rows).reset_index(drop=True)\n",
    "original_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_rows = []\n",
    "for row_data in correction_rows:\n",
    "    corrected_data = row_data.copy()\n",
    "    corrected_data[\"right_key_x\"], corrected_data[\"left_key_x\"] = corrected_data[\"left_key_x\"], corrected_data[\"right_key_x\"]\n",
    "    corrected_data[\"right_key_y\"], corrected_data[\"left_key_y\"] = corrected_data[\"left_key_y\"], corrected_data[\"right_key_y\"]\n",
    "    corrected_rows.append(corrected_data)\n",
    "\n",
    "corrected_df = pd.DataFrame(corrected_rows).reset_index(drop=True)\n",
    "\n",
    "unique_files = original_df['file_name'].unique()\n",
    "unique_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in unique_files:\n",
    "    file_original = original_df[original_df['file_name'] == file_name]\n",
    "\n",
    "    # 최대 3개까지 랜덤 추출\n",
    "    if len(file_original) > 3:\n",
    "        file_original = file_original.sample(3, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        file_original = file_original.reset_index(drop=True)\n",
    "\n",
    "    # original_index를 기준으로 corrected_df에서 동일한 샘플 추출\n",
    "    indices = file_original[\"original_index\"].tolist()\n",
    "    file_corrected = corrected_df[(corrected_df['file_name'] == file_name) &\n",
    "                                  (corrected_df['original_index'].isin(indices))].reset_index(drop=True)\n",
    "\n",
    "    num_samples = len(file_original)\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 5, 10))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.array([[axes[0]], [axes[1]]])\n",
    "\n",
    "    for idx, row in enumerate(file_original.itertuples()):\n",
    "        ax = axes[0, idx]\n",
    "        for key in keypoints:\n",
    "            ax.scatter(\n",
    "                getattr(row, f\"{key}_key_x\") * x_scale,\n",
    "                getattr(row, f\"{key}_key_y\") * y_scale,\n",
    "                color=colors[key],\n",
    "                label=key if idx == 0 else \"\",\n",
    "                s=120\n",
    "            )\n",
    "        ax.plot(\n",
    "            [row.front_key_x * x_scale, row.tail_key_x * x_scale],\n",
    "            [row.front_key_y * y_scale, row.tail_key_y * y_scale],\n",
    "            'k--', alpha=0.6\n",
    "        )\n",
    "        ax.plot(\n",
    "            [row.right_key_x * x_scale, row.left_key_x * x_scale],\n",
    "            [row.right_key_y * y_scale, row.left_key_y * y_scale],\n",
    "            'k--', alpha=0.6\n",
    "        )\n",
    "        ax.set_title(f\"Original Line {row.original_index + 1}\")\n",
    "        ax.set_xlim(0, x_scale)\n",
    "        ax.set_ylim(0, y_scale)\n",
    "        ax.grid(True)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    for idx, row in enumerate(file_corrected.itertuples()):\n",
    "        ax = axes[1, idx]\n",
    "        for key in keypoints:\n",
    "            ax.scatter(\n",
    "                getattr(row, f\"{key}_key_x\") * x_scale,\n",
    "                getattr(row, f\"{key}_key_y\") * y_scale,\n",
    "                color=colors[key],\n",
    "                s=120\n",
    "            )\n",
    "        ax.plot(\n",
    "            [row.front_key_x * x_scale, row.tail_key_x * x_scale],\n",
    "            [row.front_key_y * y_scale, row.tail_key_y * y_scale],\n",
    "            'k--', alpha=0.6\n",
    "        )\n",
    "        ax.plot(\n",
    "            [row.right_key_x * x_scale, row.left_key_x * x_scale],\n",
    "            [row.right_key_y * y_scale, row.left_key_y * y_scale],\n",
    "            'k--', alpha=0.6\n",
    "        )\n",
    "        ax.set_title(f\"Corrected Line {row.original_index + 1}\")\n",
    "        ax.set_xlim(0, x_scale)\n",
    "        ax.set_ylim(0, y_scale)\n",
    "        ax.grid(True)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig.suptitle(f\"File: {file_name}\", fontsize=16)\n",
    "\n",
    "    handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    fig.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(\"corrected_labels\")\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for frame_name, df in all_frame.items():\n",
    "    df_corrected = df.copy()\n",
    "    file_modified = False\n",
    "\n",
    "    for idx, row in df_corrected.iterrows():\n",
    "        vec_forward = np.array([\n",
    "            row[\"tail_key_x\"] - row[\"front_key_x\"],\n",
    "            row[\"tail_key_y\"] - row[\"front_key_y\"]\n",
    "        ])\n",
    "        vec_rl = np.array([\n",
    "            row[\"left_key_x\"] - row[\"right_key_x\"],\n",
    "            row[\"left_key_y\"] - row[\"right_key_y\"]\n",
    "        ])\n",
    "\n",
    "        norm_f = np.linalg.norm(vec_forward)\n",
    "        norm_rl = np.linalg.norm(vec_rl)\n",
    "\n",
    "        if norm_f == 0 or norm_rl == 0:\n",
    "            continue\n",
    "\n",
    "        vec_forward_normalized = vec_forward / norm_f\n",
    "        vec_rl_normalized = vec_rl / norm_rl\n",
    "\n",
    "        cross_z = np.cross(vec_forward_normalized, vec_rl_normalized)\n",
    "\n",
    "        if cross_z >= -threshold:\n",
    "            # 좌우 키포인트 스왑\n",
    "            df_corrected.at[idx, \"right_key_x\"], df_corrected.at[idx, \"left_key_x\"] = row[\"left_key_x\"], row[\"right_key_x\"]\n",
    "            df_corrected.at[idx, \"right_key_y\"], df_corrected.at[idx, \"left_key_y\"] = row[\"left_key_y\"], row[\"right_key_y\"]\n",
    "            file_modified = True\n",
    "\n",
    "    if file_modified:\n",
    "        # YOLO 형식으로 텍스트 저장\n",
    "        save_path = save_dir / f\"{frame_name}.txt\"\n",
    "        with open(save_path, \"w\") as f:\n",
    "            for _, row in df_corrected.iterrows():\n",
    "                yolo_line = \" \".join(map(str, row.values.tolist()))\n",
    "                f.write(yolo_line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 상수 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATHS = Path('D:/생육거점 데이터/infrared_of/images/roboflow/asd.v20i.yolov8/test/labels/')\n",
    "COLUMN_NAMES = [\n",
    "    \"class\", \"x_center\", \"y_center\", \"width\", \"height\",\n",
    "    \"front_key_x\", \"front_key_y\", \"front_key_vis\",\n",
    "    \"tail_key_x\", \"tail_key_y\", \"tail_key_vis\",\n",
    "    \"right_key_x\", \"right_key_y\", \"right_key_vis\",\n",
    "    \"left_key_x\", \"left_key_y\", \"left_key_vis\"\n",
    "]\n",
    "THRESHOLD = 1e-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 1. 데이터 불러오기 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_all_labels(label_dir: Path):\n",
    "    \"\"\"\n",
    "    지정된 디렉터리 내의 모든 텍스트 파일을 읽어들여,\n",
    "    파일의 stem을 key, DataFrame을 value로 갖는 딕셔너리를 반환합니다.\n",
    "    \"\"\"\n",
    "    all_frames = {}\n",
    "    for label_file in label_dir.glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            data = [list(map(float, line.strip().split())) for line in lines if line.strip()]\n",
    "        df = pd.DataFrame(data, columns=COLUMN_NAMES)\n",
    "        all_frames[label_file.stem] = df\n",
    "    return all_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_data(label_dir: Path):\n",
    "    \"\"\"\n",
    "    모든 텍스트 파일의 데이터를 하나의 DataFrame으로 결합하여 반환합니다.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for label_file in label_dir.glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    numbers = list(map(float, line.strip().split()))\n",
    "                    all_data.append(numbers)\n",
    "    df = pd.DataFrame(all_data, columns=COLUMN_NAMES)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 2. 오류 검출 및 수정 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_z(row):\n",
    "    \"\"\"\n",
    "    전방 벡터 (tail_key - front_key)와 좌우 벡터 (left_key - right_key)를 정규화한 후,\n",
    "    두 벡터의 외적(z 성분)을 계산합니다.\n",
    "    \"\"\"\n",
    "    vec_forward = np.array([row[\"tail_key_x\"] - row[\"front_key_x\"],\n",
    "                            row[\"tail_key_y\"] - row[\"front_key_y\"]])\n",
    "    vec_rl = np.array([row[\"left_key_x\"] - row[\"right_key_x\"],\n",
    "                       row[\"left_key_y\"] - row[\"right_key_y\"]])\n",
    "    norm_f = np.linalg.norm(vec_forward)\n",
    "    norm_rl = np.linalg.norm(vec_rl)\n",
    "    if norm_f == 0 or norm_rl == 0:\n",
    "        return None\n",
    "    vec_forward_norm = vec_forward / norm_f\n",
    "    vec_rl_norm = vec_rl / norm_rl\n",
    "    cross_z = np.cross(vec_forward_norm, vec_rl_norm)\n",
    "    return cross_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_indices(df, threshold=THRESHOLD):\n",
    "    \"\"\"\n",
    "    DataFrame의 각 행에 대해 외적 결과가 임계값 조건을 만족하면 해당 인덱스를 반환합니다.\n",
    "    \"\"\"\n",
    "    error_indices = []\n",
    "    for idx, row in df.iterrows():\n",
    "        cross_z = compute_cross_z(row)\n",
    "        if cross_z is None:\n",
    "            continue\n",
    "        if cross_z > -threshold:\n",
    "            error_indices.append(idx)\n",
    "    return error_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_dataframe(df, threshold=THRESHOLD):\n",
    "    \"\"\"\n",
    "    각 행의 외적 결과가 임계값 이상일 경우 좌우 키포인트를 스왑하여 수정한 DataFrame을 반환합니다.\n",
    "    수정이 발생하면 file_modified 플래그가 True로 설정됩니다.\n",
    "    \"\"\"\n",
    "    df_corrected = df.copy()\n",
    "    file_modified = False\n",
    "    for idx, row in df_corrected.iterrows():\n",
    "        cross_z = compute_cross_z(row)\n",
    "        if cross_z is None:\n",
    "            continue\n",
    "        if cross_z >= -threshold:\n",
    "            # 좌우 키포인트 스왑\n",
    "            df_corrected.at[idx, \"right_key_x\"], df_corrected.at[idx, \"left_key_x\"] = row[\"left_key_x\"], row[\"right_key_x\"]\n",
    "            df_corrected.at[idx, \"right_key_y\"], df_corrected.at[idx, \"left_key_y\"] = row[\"left_key_y\"], row[\"right_key_y\"]\n",
    "            file_modified = True\n",
    "    return df_corrected, file_modified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 3. 수정된 라벨 파일 저장 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corrected_labels(all_frames, save_dir_path=\"corrected_labels\", threshold=THRESHOLD):\n",
    "    \"\"\"\n",
    "    각 파일의 DataFrame을 수정하여 저장합니다.\n",
    "    수정이 발생한 경우에만 파일이 저장되며, YOLO 형식의 텍스트 파일로 기록합니다.\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir_path)\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for file_name, df in all_frames.items():\n",
    "        df_corrected, file_modified = correct_dataframe(df, threshold)\n",
    "        if file_modified:\n",
    "            save_path = save_dir / f\"{file_name}.txt\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                for _, row in df_corrected.iterrows():\n",
    "                    yolo_line = \" \".join(map(str, row.values.tolist()))\n",
    "                    f.write(yolo_line + \"\\n\")\n",
    "            print(f\"수정된 파일 저장됨: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 4. 메인 실행부\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # (1) 데이터 결합 및 기본 통계 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = combine_all_data(LABEL_PATHS)\n",
    "print(\"결합된 데이터 미리보기:\")\n",
    "print(df_combined.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df_combined.info())\n",
    "print(\"\\nDataFrame 기술 통계:\")\n",
    "print(df_combined.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # (2) 오류 데이터 판별\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_indices = get_error_indices(df_combined, THRESHOLD)\n",
    "df_errors = df_combined.loc[error_indices].reset_index(drop=True)\n",
    "print(\"\\n오류 데이터:\")\n",
    "print(df_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # (3) 전체 프레임 데이터 불러오기 및 수정된 라벨 파일 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = load_all_labels(LABEL_PATHS)\n",
    "save_corrected_labels(all_frames, save_dir_path=\"corrected_labels\", threshold=THRESHOLD)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
