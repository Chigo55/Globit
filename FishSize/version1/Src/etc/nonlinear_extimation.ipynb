{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import mimetypes\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from abc import ABCMeta, abstractmethod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('./weight_all_class/weights/best.pt')\n",
    "depth_anything = DepthAnythingV2(**model_configs['vits']).to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_anything.load_state_dict(torch.load(f'checkpoints/depth_anything_v2_{\"vits\"}.pth', map_location='cpu'))\n",
    "depth_anything = depth_anything.to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_img/Untitled.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = yolo.predict(\n",
    "    source=img, save=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = depth_anything.infer_image(img)\n",
    "depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
    "depth = depth.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dict = dict()\n",
    "\n",
    "for r in results:\n",
    "    r_dict = {idx: list(map(int, bbox)) for idx, bbox in enumerate(r.boxes.xyxy.squeeze().tolist())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plotImageRGB(image: list):\n",
    "    plt.imshow(image)\n",
    "    plt.axis(False)\n",
    "\n",
    "\n",
    "def plotImageGRAY(image: list):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImageRGB(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImageGRAY(depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(background, cmap='gray')\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(background, (r_dict[0][:2]), (r_dict[0][2:]), 255, -1)\n",
    "plt.imshow(background, cmap='gray')\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_depth = cv2.bitwise_and(depth, depth, mask=background)\n",
    "plotImageGRAY(fish_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, otsu_depth = cv2.threshold(fish_depth, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "plotImageGRAY(otsu_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(otsu_depth, 0, 255)\n",
    "edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges, cmap='gray')\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "edge = max(contours, key=cv2.contourArea)\n",
    "background = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges), type(edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.fillPoly(background, pts=[edges[0]], color=(255, 255, 255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.drawContours(background, [edge], -1, (255, 255, 255), thickness=cv2.FILLED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImageGRAY(background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 4. 컨투어 좌표를 추출하고 PCA 수행\n",
    "\n",
    "# 컨투어의 좌표를 (x, y) 배열로 변환\n",
    "contour_points = np.squeeze(edge)\n",
    "\n",
    "# PCA 적용\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(contour_points)\n",
    "\n",
    "# 주성분 축을 시각화하기 위한 계산\n",
    "center = np.mean(contour_points, axis=0)\n",
    "eigenvectors = pca.components_  # 주성분 방향\n",
    "eigenvalues = pca.explained_variance_  # 주성분 크기\n",
    "\n",
    "# 결과 시각화를 위한 출력 이미지 생성\n",
    "output_image = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# 5. 컨투어 그리기\n",
    "cv2.drawContours(output_image, [edge], -1, (0, 255, 0), 2)\n",
    "\n",
    "# 6. 주성분 축 시각화\n",
    "scale = 100  # 주성분 축을 시각적으로 확장하는 스케일링\n",
    "for eigenvalue, eigenvector in zip(eigenvalues, eigenvectors):\n",
    "    # 주성분 축의 시작과 끝 좌표 계산\n",
    "    endpoint = center + eigenvector * np.sqrt(eigenvalue) * scale\n",
    "\n",
    "    # 주성분 축 그리기 (파란색 선)\n",
    "    cv2.line(output_image, tuple(center.astype(int)), tuple(endpoint.astype(int)), (255, 0, 0), 2)\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('PCA on Contours'), plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def find_tail_split_point(contour):\n",
    "    \"\"\"\n",
    "    컨투어에서 두 주성분에 가장 가까운 점을 찾아 물고기 꼬리의 갈라진 중앙점을 반환하는 함수\n",
    "    \"\"\"\n",
    "    # 1. 컨투어 좌표 추출 (N x 2 배열)\n",
    "    contour_points = np.squeeze(contour)\n",
    "\n",
    "    # PCA 적용 (주성분 분석)\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(contour_points)\n",
    "\n",
    "    # 주성분 축\n",
    "    center = np.mean(contour_points, axis=0)  # 중심점\n",
    "    eigenvectors = pca.components_  # 주성분 벡터 (2개의 주성분)\n",
    "    eigenvalues = pca.explained_variance_  # 주성분에 대한 분산 (크기)\n",
    "\n",
    "    # 2. 주성분 벡터로부터 컨투어의 각 점까지의 거리 계산\n",
    "    def point_distance_to_line(point, line_vector, line_point):\n",
    "        # 선분과 점 사이의 직선 거리를 계산\n",
    "        point = np.array(point)\n",
    "        line_vector = np.array(line_vector)\n",
    "        line_point = np.array(line_point)\n",
    "\n",
    "        # 두 벡터 간의 크로스 프로덕트를 사용해 거리를 계산\n",
    "        distance = np.linalg.norm(np.cross(line_vector, line_point - point)) / np.linalg.norm(line_vector)\n",
    "        return distance\n",
    "\n",
    "    # 첫 번째 주성분과 두 번째 주성분에 대한 거리 계산\n",
    "    distances_to_first_pc = [point_distance_to_line(p, eigenvectors[0], center) for p in contour_points]\n",
    "    distances_to_second_pc = [point_distance_to_line(p, eigenvectors[1], center) for p in contour_points]\n",
    "\n",
    "    # 3. 첫 번째 주성분에 대해 먼저 정렬, 그 후 두 번째 주성분 기준으로 추가 정렬\n",
    "    sorted_points = sorted(contour_points, key=lambda p: (\n",
    "        point_distance_to_line(p, eigenvectors[0], center),  # 첫 번째 주성분 기준 정렬\n",
    "        point_distance_to_line(p, eigenvectors[1], center)   # 두 번째 주성분 기준 추가 정렬\n",
    "    ), )\n",
    "\n",
    "    # 첫 번째 주성분과 두 번째 주성분과 가장 가까운 점 선택\n",
    "    closest_point = sorted_points[1]\n",
    "\n",
    "    return closest_point, center, eigenvectors, sorted_points\n",
    "\n",
    "\n",
    "# 가장 큰 컨투어 선택\n",
    "contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# 함수 호출하여 꼬리 중앙점 찾기\n",
    "tail_split_point, center, eigenvectors, sorted_points = find_tail_split_point(contour)\n",
    "\n",
    "# 시각화\n",
    "output_image = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawContours(output_image, [contour], -1, (0, 255, 0), 2)  # 컨투어 그리기\n",
    "cv2.circle(output_image, tuple(tail_split_point.astype(int)), 5, (0, 0, 255), -1)  # 꼬리 중앙점 표시 (빨간색)\n",
    "\n",
    "# 주성분 축 그리기\n",
    "scale = 100\n",
    "for eigenvalue, eigenvector in zip(eigenvectors, eigenvectors):\n",
    "    endpoint = center + eigenvector * scale\n",
    "    cv2.line(output_image, tuple(center.astype(int)), tuple(endpoint.astype(int)), (255, 0, 0), 2)  # 파란색 주성분 축\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Fish Tail Split Point Detection'), plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV에서 제공하는 다양한 커널을 사용하여 erode 연산을 적용하는 예시를 보여줍니다.\n",
    "kernels = {\n",
    "    \"Rectangular (5x5)\": cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)),\n",
    "    \"Elliptical (5x5)\": cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)),\n",
    "    \"Cross-shaped (5x5)\": cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화를 위한 준비\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 원본 이미지 시각화\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(background, cmap='gray')\n",
    "plt.title('Original Binary Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# 각 커널에 대해 erode 연산을 적용하고 시각화\n",
    "for i, (name, kernel) in enumerate(kernels.items(), start=2):\n",
    "    eroded_image = cv2.erode(background, kernel, iterations=5)\n",
    "\n",
    "    # 시각화\n",
    "    plt.subplot(1, 4, i)\n",
    "    plt.imshow(eroded_image, cmap='gray')\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"이미지를 불러올 수 없습니다.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        11, 2\n",
    "    )\n",
    "    return thresh\n",
    "\n",
    "\n",
    "def detect_edges(thresh_image):\n",
    "    edges = cv2.Canny(thresh_image, 50, 150, apertureSize=3)\n",
    "    return edges\n",
    "\n",
    "\n",
    "def detect_lines(edges):\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges,\n",
    "        rho=1,\n",
    "        theta=np.pi / 180,\n",
    "        threshold=50,\n",
    "        minLineLength=50,\n",
    "        maxLineGap=10\n",
    "    )\n",
    "    return lines\n",
    "\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    line_img = image.copy()\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(line_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "def find_split_points(lines):\n",
    "    if lines is None:\n",
    "        return []\n",
    "\n",
    "    start_points = [(line[0][0], line[0][1]) for line in lines]\n",
    "\n",
    "    clustering = DBSCAN(eps=10, min_samples=2).fit(start_points)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    split_points = []\n",
    "    for label in set(labels):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        points = np.array(start_points)[labels == label]\n",
    "        centroid = points.mean(axis=0).astype(int)\n",
    "        split_points.append(tuple(centroid))\n",
    "\n",
    "    return split_points\n",
    "\n",
    "\n",
    "def visualize_results(original_image, edges, line_image, split_points):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title('Edge Detection')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(cv2.cvtColor(line_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Detected Lines')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    for point in split_points:\n",
    "        plt.scatter(point[0], point[1], c='red', s=100, marker='x')\n",
    "    plt.title('Split Points')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main(image_path):\n",
    "    thresh = preprocess_image(image_path)\n",
    "    if thresh is None:\n",
    "        return\n",
    "\n",
    "    edges = detect_edges(thresh)\n",
    "    lines = detect_lines(edges)\n",
    "    original = cv2.imread(image_path)\n",
    "    line_image = draw_lines(original, lines)\n",
    "    split_points = find_split_points(lines)\n",
    "    visualize_results(original, edges, line_image, split_points)\n",
    "\n",
    "    print(\"찾은 갈라진 지점:\", split_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('./test_img/Untitled.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
