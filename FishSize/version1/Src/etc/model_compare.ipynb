{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_size.depth_anything.dpt import DepthAnything\n",
    "from fish_size.depth_anything.util.transform import Resize, NormalizeImage, PrepareForNet\n",
    "\n",
    "from fish_size.depth_anything_v2.dpt import DepthAnythingV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DepthAnything.from_pretrained('LiheYoung/depth_anything_{}14'.format('vitl')).to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da2 = DepthAnythingV2(**model_configs['vitl'])\n",
    "da2.load_state_dict(torch.load(f'./fish_size/checkpoints/depth_anything_v2_{\"vitl\"}.pth', map_location='cpu'))\n",
    "da2 = da2.to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize(\n",
    "        width=518,\n",
    "        height=518,\n",
    "        resize_target=False,\n",
    "        keep_aspect_ratio=True,\n",
    "        ensure_multiple_of=14,\n",
    "        resize_method='lower_bound',\n",
    "        image_interpolation_method=cv2.INTER_CUBIC,\n",
    "    ),\n",
    "    NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    PrepareForNet(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('dataset/images/test/objt_rs.JPG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "h, w = rgb_image.shape[:2]\n",
    "\n",
    "rgb_image = transform({'image': rgb_image})['image']\n",
    "rgb_image = torch.from_numpy(rgb_image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    depth_da = da(rgb_image)\n",
    "\n",
    "depth_da = F.interpolate(depth_da[None], (h, w), mode='bilinear', align_corners=False)[0, 0]\n",
    "depth_da = (depth_da - depth_da.min()) / (depth_da.max() - depth_da.min()) * 255.0\n",
    "\n",
    "depth_da = depth_da.cpu().numpy().astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_da2 = da2.infer_image(image, 518)\n",
    "\n",
    "depth_da2 = (depth_da2 - depth_da2.min()) / (depth_da2.max() - depth_da2.min()) * 255.0\n",
    "depth_da2 = depth_da2.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_da_g = np.repeat(depth_da[..., np.newaxis], 3, axis=-1)\n",
    "depth_da2_g = np.repeat(depth_da2[..., np.newaxis], 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colormaps.get_cmap('Spectral_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_da_c_l = (cmap(depth_da)[:, :, :3] * 255)[:, :, ::-1].astype(np.uint8)\n",
    "depth_da2_c_l = (cmap(depth_da2)[:, :, :3] * 255)[:, :, ::-1].astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageWrite(image1, image2, filename):\n",
    "    split_region = np.ones((image1.shape[0], 50, 3), dtype=np.uint8) * 255\n",
    "    combined_result = cv2.hconcat([image1, split_region, image2])\n",
    "\n",
    "    cv2.imwrite(os.path.join('./runs/vis_depth', os.path.splitext(os.path.basename(filename))[0] + '.png'), combined_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageWrite(depth_da_g, depth_da_c_l, 'DA_L')\n",
    "imageWrite(depth_da2_g, depth_da2_c_l, \"DA2_L\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# 베이스 디렉토리 설정\n",
    "base_dir = 'dataset/images'\n",
    "\n",
    "# 하위 폴더 목록\n",
    "subfolders = ['bp', 'kr', 'of', 'rb', 'rs']\n",
    "\n",
    "# 각 폴더에서 읽을 이미지 수\n",
    "images_per_folder = 50\n",
    "\n",
    "# 이미지 경로를 저장할 리스트\n",
    "image_paths = []\n",
    "\n",
    "# 각 하위 폴더 순회\n",
    "for subfolder in subfolders:\n",
    "    folder_path = os.path.join(base_dir, subfolder)\n",
    "    # 이미지 파일 목록 가져오기\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "    # 이미지 파일이 20개 이상인지 확인\n",
    "    if len(image_files) >= images_per_folder:\n",
    "        # 20개의 이미지를 무작위로 선택\n",
    "        selected_images = random.sample(image_files, images_per_folder)\n",
    "        # 선택된 이미지의 전체 경로를 리스트에 추가\n",
    "        for image_file in selected_images:\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            image_paths.append(image_path)\n",
    "    else:\n",
    "        # 이미지가 20장 미만인 경우 폴더를 건너뜀\n",
    "        print(f\"폴더 '{subfolder}'는 이미지가 {images_per_folder}장 미만이므로 건너뜁니다.\")\n",
    "\n",
    "# 결과 확인 (선택 사항)\n",
    "print(f\"총 {len(image_paths)}개의 이미지 경로가 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "for i in image_paths:\n",
    "    image = cv2.imread(i)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "    h, w = rgb_image.shape[:2]\n",
    "\n",
    "    rgb_image = transform({'image': rgb_image})['image']\n",
    "    rgb_image = torch.from_numpy(rgb_image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        depth_da = da(rgb_image)\n",
    "\n",
    "    depth_da = F.interpolate(depth_da[None], (h, w), mode='bilinear', align_corners=False)[0, 0]\n",
    "    depth_da = (depth_da - depth_da.min()) / (depth_da.max() - depth_da.min()) * 255.0\n",
    "\n",
    "    depth_da = depth_da.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "end = perf_counter()\n",
    "print(f'Elapsed time: {end - start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "for i in image_paths:\n",
    "    image = cv2.imread(i)\n",
    "\n",
    "    depth_da2 = da2.infer_image(image, 518)\n",
    "\n",
    "    depth_da2 = (depth_da2 - depth_da2.min()) / (depth_da2.max() - depth_da2.min()) * 255.0\n",
    "    depth_da2 = depth_da2.astype(np.uint8)\n",
    "\n",
    "end = perf_counter()\n",
    "print(f'Elapsed time: {end - start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DepthAnything.from_pretrained('LiheYoung/depth_anything_{}14'.format('vits')).to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da2 = DepthAnythingV2(**model_configs['vits'])\n",
    "da2.load_state_dict(torch.load(f'./fish_size/checkpoints/depth_anything_v2_{\"vits\"}.pth', map_location='cpu'))\n",
    "da2 = da2.to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "h, w = rgb_image.shape[:2]\n",
    "\n",
    "rgb_image = transform({'image': rgb_image})['image']\n",
    "rgb_image = torch.from_numpy(rgb_image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    depth_da = da(rgb_image)\n",
    "\n",
    "depth_da = F.interpolate(depth_da[None], (h, w), mode='bilinear', align_corners=False)[0, 0]\n",
    "depth_da = (depth_da - depth_da.min()) / (depth_da.max() - depth_da.min()) * 255.0\n",
    "\n",
    "depth_da = depth_da.cpu().numpy().astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_da2 = da2.infer_image(image, 518)\n",
    "\n",
    "depth_da2 = (depth_da2 - depth_da2.min()) / (depth_da2.max() - depth_da2.min()) * 255.0\n",
    "depth_da2 = depth_da2.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_da_g = np.repeat(depth_da[..., np.newaxis], 3, axis=-1)\n",
    "depth_da2_g = np.repeat(depth_da2[..., np.newaxis], 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colormaps.get_cmap('Spectral_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_da_c_s = (cmap(depth_da)[:, :, :3] * 255)[:, :, ::-1].astype(np.uint8)\n",
    "depth_da2_c_s = (cmap(depth_da2)[:, :, :3] * 255)[:, :, ::-1].astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageWrite(depth_da_g, depth_da_c_l, 'DA_S')\n",
    "imageWrite(depth_da2_g, depth_da2_c_l, \"DA2_S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageWrite(depth_da_c_s, depth_da_c_l, 'DA')\n",
    "imageWrite(depth_da2_c_s, depth_da2_c_l, \"DA2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "for i in image_paths:\n",
    "    image = cv2.imread(i)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "    h, w = rgb_image.shape[:2]\n",
    "\n",
    "    rgb_image = transform({'image': rgb_image})['image']\n",
    "    rgb_image = torch.from_numpy(rgb_image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        depth_da = da(rgb_image)\n",
    "\n",
    "    depth_da = F.interpolate(depth_da[None], (h, w), mode='bilinear', align_corners=False)[0, 0]\n",
    "    depth_da = (depth_da - depth_da.min()) / (depth_da.max() - depth_da.min()) * 255.0\n",
    "\n",
    "    depth_da = depth_da.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "end = perf_counter()\n",
    "print(f'Elapsed time: {end - start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "for i in image_paths:\n",
    "    image = cv2.imread(i)\n",
    "\n",
    "    depth_da2 = da2.infer_image(image, 518)\n",
    "\n",
    "    depth_da2 = (depth_da2 - depth_da2.min()) / (depth_da2.max() - depth_da2.min()) * 255.0\n",
    "    depth_da2 = depth_da2.astype(np.uint8)\n",
    "\n",
    "end = perf_counter()\n",
    "print(f'Elapsed time: {end - start}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
