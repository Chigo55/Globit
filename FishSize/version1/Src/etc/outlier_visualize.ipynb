{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Path(\"runs/predict\")\n",
    "paths = [folder for folder in source.rglob('*') if folder.is_dir()]\n",
    "csv = list(chain.from_iterable(path.glob(f\"{path.name}_merged_output.csv\") for path in paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Function to visualize data from multiple CSV files / 여러 CSV 파일의 데이터를 시각화하는 함수\n",
    "\n",
    "\n",
    "def outlier_visualize_combined(csv_paths: List[Path]) -> None:\n",
    "    num_files = len(csv_paths)\n",
    "\n",
    "    # Create a figure for subplots / 서브플롯을 위한 전체 figure 생성\n",
    "    fig, axes = plt.subplots(3, num_files, figsize=(5 * num_files, 15))\n",
    "\n",
    "    # Iterate through each CSV file / 각 CSV 파일을 순회\n",
    "    for idx, path in enumerate(csv_paths):\n",
    "        data = pd.read_csv(path)\n",
    "\n",
    "        # First row: Width histogram / 첫 번째 행: Width 히스토그램\n",
    "        axes[0, idx].hist(data['Width'], bins=50, alpha=0.6, color='blue')\n",
    "        axes[0, idx].set_title(f'Width Histogram - {path.name}')\n",
    "        axes[0, idx].set_xlabel('Width')\n",
    "        axes[0, idx].set_ylabel('Frequency')\n",
    "\n",
    "        # Second row: Height histogram / 두 번째 행: Height 히스토그램\n",
    "        axes[1, idx].hist(data['Height'], bins=50, alpha=0.6, color='green')\n",
    "        axes[1, idx].set_title(f'Height Histogram - {path.name}')\n",
    "        axes[1, idx].set_xlabel('Height')\n",
    "        axes[1, idx].set_ylabel('Frequency')\n",
    "\n",
    "        # Third row: Scatter plot / 세 번째 행: Width vs Height 스캐터 플롯\n",
    "        axes[2, idx].scatter(data['Width'], data['Height'], alpha=0.3, c='red')\n",
    "        axes[2, idx].set_title(f'Scatter Plot - {path.name}')\n",
    "        axes[2, idx].set_xlabel('Width')\n",
    "        axes[2, idx].set_ylabel('Height')\n",
    "        axes[2, idx].grid(True)\n",
    "\n",
    "    # Adjust layout and display the plots / 레이아웃 조정 및 플롯 표시\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_visualize_combined(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier removal function / 이상치 제거 함수\n",
    "def remove_outliers(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Function to visualize boxplots for multiple CSV files / 여러 CSV 파일의 박스플롯을 시각화하는 함수\n",
    "\n",
    "\n",
    "def boxplot_visualize_combined(csv_paths: List[Path]) -> None:\n",
    "    num_files = len(csv_paths)\n",
    "\n",
    "    # Create a figure for subplots with 2 rows / 서브플롯을 위한 2행 전체 figure 생성\n",
    "    fig, axes = plt.subplots(2, num_files, figsize=(5 * num_files, 10))\n",
    "\n",
    "    # Iterate through each CSV file / 각 CSV 파일을 순회\n",
    "    for idx, path in enumerate(csv_paths):\n",
    "        data = pd.read_csv(path)\n",
    "\n",
    "        # First row: Boxplot for Width and Height before outlier removal / 첫 번째 행: 이상치 제거 전 Width와 Height에 대한 박스플롯\n",
    "        data[['Width', 'Height']].boxplot(ax=axes[0, idx])\n",
    "        axes[0, idx].set_title(f'Boxplot Before Outlier Removal - {path.name}')\n",
    "\n",
    "        # Remove outliers for Width and Height / Width 및 Height에 대한 이상치 제거\n",
    "        data_no_outliers = data.copy()\n",
    "        data_no_outliers = remove_outliers(data_no_outliers, 'Width')\n",
    "        data_no_outliers = remove_outliers(data_no_outliers, 'Height')\n",
    "\n",
    "        # Second row: Boxplot for Width and Height after outlier removal / 두 번째 행: 이상치 제거 후 Width와 Height에 대한 박스플롯\n",
    "        data_no_outliers[['Width', 'Height']].boxplot(ax=axes[1, idx])\n",
    "        axes[1, idx].set_title(f'Boxplot After Outlier Removal - {path.name}')\n",
    "\n",
    "    # Adjust layout and display the plots / 레이아웃 조정 및 플롯 표시\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_visualize_combined(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Path(\"runs/predict2\")\n",
    "paths = [folder for folder in source.rglob('*') if folder.is_dir()]\n",
    "csv = list(chain.from_iterable(path.glob(f\"{path.name}_merged_output.csv\") for path in paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_visualize_combined(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_visualize_combined(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 병합할 CSV 파일들이 있는 디렉토리 경로를 입력하세요.\n",
    "input_folder = Path('./runs/predict/exp')\n",
    "\n",
    "# 병합된 CSV 파일을 저장할 파일명을 입력하세요.\n",
    "output_file = '_merged_output.csv'\n",
    "\n",
    "# 지정된 디렉토리 내의 모든 CSV 파일 목록을 가져옵니다.\n",
    "csv_files = sorted(input_folder.glob('*.csv'))\n",
    "\n",
    "# 데이터프레임을 저장할 리스트를 초기화합니다.\n",
    "dataframes = []\n",
    "\n",
    "# CSV 파일들을 순회하며 데이터프레임으로 읽어들입니다.\n",
    "for idx, file in enumerate(csv_files):\n",
    "    if idx == 0:\n",
    "        # 첫 번째 파일은 헤더를 포함하여 읽어옵니다.\n",
    "        df = pd.read_csv(file)\n",
    "    else:\n",
    "        # 이후 파일들은 헤더를 스킵하고 읽어옵니다.\n",
    "        df = pd.read_csv(file, skiprows=1, header=None)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# 데이터프레임들을 하나로 병합합니다.\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 첫 번째 데이터프레임의 컬럼명을 사용하도록 헤더를 설정합니다.\n",
    "merged_df.columns = dataframes[0].columns\n",
    "\n",
    "# 병합된 데이터프레임을 CSV 파일로 저장합니다.\n",
    "output_file = input_folder.name / output_file\n",
    "\n",
    "merged_df.to_csv(output_file, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Path(\"runs/predict2/predict2_merged_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(source)\n",
    "data[['Width', 'Height']].boxplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_outliers = data.copy()\n",
    "data_no_outliers = remove_outliers(data_no_outliers, 'Width')\n",
    "data_no_outliers = remove_outliers(data_no_outliers, 'Height')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_outliers[['Width', 'Height']].boxplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# model = YOLO(\"./fish_size/checkpoints/best.pt\")\n",
    "\n",
    "# metrics = model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "model = YOLO('./fish_size/checkpoints/best.pt')\n",
    "\n",
    "source = Path('./dataset/test_img')\n",
    "paths = [folder for folder in source.rglob('*') if folder.is_dir()]\n",
    "\n",
    "for path in paths:\n",
    "    results = model.predict(\n",
    "        source=path,\n",
    "        save=True,\n",
    "        save_txt=True,\n",
    "        stream=True,\n",
    "        verbose=False,\n",
    "        conf=0.75,\n",
    "        iou=0.75\n",
    "    )\n",
    "\n",
    "    for result in results:\n",
    "        print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
